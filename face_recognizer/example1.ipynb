{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret,frame = capture.read(0)\n",
    "    cv2.imshow('image',frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('kang'+str(i)+'.jpg',frame)\n",
    "    \n",
    "        \n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image1.jpg\n",
      "image2.jpg\n",
      "image3.jpg\n",
      "image4.jpg\n",
      "image5.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "frameFrequency=25\n",
    "\n",
    "\n",
    "total_frame = 0\n",
    "id = 0\n",
    "while True:\n",
    "    if id<5:\n",
    "        \n",
    "        \n",
    "        \n",
    "        ret, frame = cap.read(0)\n",
    "        cv2.imshow('image',frame)\n",
    "        if ret is False:\n",
    "            break\n",
    "        total_frame += 1\n",
    "        if total_frame%frameFrequency == 0:\n",
    "            id += 1\n",
    "            image_name = \"image\" + str(id) +'.jpg'\n",
    "            cv2.imwrite(image_name, frame)\n",
    "            print(image_name)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245 168 184 184]]\n",
      "[[247 171 181 181]]\n",
      "[[247 170 181 181]]\n",
      "[[243 169 185 185]]\n",
      "[[245 171 182 182]]\n",
      "[[244 169 183 183]]\n",
      "[[242 169 186 186]]\n",
      "[[245 171 181 181]]\n",
      "[[243 169 184 184]]\n",
      "[[244 170 182 182]]\n",
      "[[246 171 180 180]]\n",
      "[[244 171 181 181]]\n",
      "[[244 171 181 181]]\n",
      "[[243 170 183 183]]\n",
      "[[241 169 184 184]]\n",
      "[[243 171 180 180]]\n",
      "[[237 168 187 187]]\n",
      "[[237 168 186 186]]\n",
      "[[234 167 187 187]]\n",
      "[[234 168 185 185]]\n",
      "[[229 165 188 188]]\n",
      "[[228 164 190 190]]\n",
      "[[227 163 189 189]]\n",
      "[[227 165 186 186]]\n",
      "[[227 165 185 185]]\n",
      "user1.jpg\n",
      "[[223 164 189 189]]\n",
      "[[225 165 185 185]]\n",
      "[[224 164 187 187]]\n",
      "[[224 164 187 187]]\n",
      "[[224 165 186 186]]\n",
      "[[223 163 188 188]]\n",
      "[[223 163 188 188]]\n",
      "[[222 163 188 188]]\n",
      "[[223 163 188 188]]\n",
      "[[222 162 189 189]]\n",
      "[[223 163 187 187]]\n",
      "[[224 163 186 186]]\n",
      "[[224 163 187 187]]\n",
      "[[226 164 185 185]]\n",
      "[[227 164 184 184]]\n",
      "[[226 163 187 187]]\n",
      "[[227 164 185 185]]\n",
      "[[226 163 185 185]]\n",
      "[[228 163 185 185]]\n",
      "[[229 164 185 185]]\n",
      "[[230 165 184 184]]\n",
      "[[229 165 184 184]]\n",
      "[[231 166 182 182]]\n",
      "[[231 165 182 182]]\n",
      "[[231 164 184 184]]\n",
      "user2.jpg\n",
      "[[231 165 184 184]]\n",
      "[[231 166 183 183]]\n",
      "[[234 167 181 181]]\n",
      "[[232 166 183 183]]\n",
      "[[232 165 185 185]]\n",
      "[[234 166 184 184]]\n",
      "[[235 166 183 183]]\n",
      "[[235 166 181 181]]\n",
      "[[234 164 183 183]]\n",
      "[[232 165 183 183]]\n",
      "[[234 164 181 181]]\n",
      "[[233 165 180 180]]\n",
      "[[233 165 180 180]]\n",
      "[[232 165 182 182]]\n",
      "[[232 165 181 181]]\n",
      "[[231 165 181 181]]\n",
      "[[229 163 185 185]]\n",
      "[[228 164 186 186]]\n",
      "[[228 164 186 186]]\n",
      "[[226 163 188 188]]\n",
      "[[226 164 187 187]]\n",
      "[[224 162 190 190]]\n",
      "[[225 163 187 187]]\n",
      "[[224 163 186 186]]\n",
      "[[223 162 189 189]]\n",
      "user3.jpg\n",
      "[[222 161 189 189]]\n",
      "[[224 163 187 187]]\n",
      "[[222 162 190 190]]\n",
      "[[225 163 187 187]]\n",
      "[[224 163 187 187]]\n",
      "[[224 163 186 186]]\n",
      "[[226 163 186 186]]\n",
      "[[225 163 187 187]]\n",
      "[[226 164 184 184]]\n",
      "[[225 163 186 186]]\n",
      "[[226 165 184 184]]\n",
      "[[227 164 185 185]]\n",
      "[[227 165 185 185]]\n",
      "[[227 163 185 185]]\n",
      "[[228 164 184 184]]\n",
      "[[228 164 183 183]]\n",
      "[[228 164 184 184]]\n",
      "[[226 163 187 187]]\n",
      "[[228 163 185 185]]\n",
      "[[229 164 185 185]]\n",
      "[[229 164 184 184]]\n",
      "[[228 164 185 185]]\n",
      "[[228 164 184 184]]\n",
      "[[228 164 184 184]]\n",
      "[[228 163 184 184]]\n",
      "user4.jpg\n",
      "[[227 162 186 186]]\n",
      "[[228 163 184 184]]\n",
      "[[227 163 185 185]]\n",
      "[[227 162 186 186]]\n",
      "[[228 163 184 184]]\n",
      "[[228 162 184 184]]\n",
      "[[228 162 184 184]]\n",
      "[[229 163 184 184]]\n",
      "[[229 163 184 184]]\n",
      "[[230 163 183 183]]\n",
      "[[229 163 184 184]]\n",
      "[[229 163 184 184]]\n",
      "[[229 163 184 184]]\n",
      "[[229 162 184 184]]\n",
      "[[229 162 184 184]]\n",
      "[[229 163 183 183]]\n",
      "[[229 162 184 184]]\n",
      "[[229 162 184 184]]\n",
      "[[229 162 184 184]]\n",
      "[[228 161 187 187]]\n",
      "[[228 161 187 187]]\n",
      "[[233 162 183 183]]\n",
      "[[234 162 182 182]]\n",
      "[[233 163 183 183]]\n",
      "[[233 162 184 184]]\n",
      "user5.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def draw_rect(img, faces, sf=20):\n",
    "    for x, y, w, h in faces:\n",
    "        x = x - sf\n",
    "        y = y - 2*sf\n",
    "        cv2.rectangle(img, (x,y), (x+w+2*sf, y+h+3*sf), (255, 0 , 0), 3)\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "frameFrequency=25\n",
    "total_frame = 0\n",
    "id = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read(0)\n",
    "\n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    faces = face_detector.detectMultiScale(frame, 1.1, 4)\n",
    "    print(faces)\n",
    "\n",
    "    draw_rect(frame, faces)\n",
    "    \n",
    "    total_frame += 1\n",
    "    if total_frame%frameFrequency == 0:\n",
    "        id += 1\n",
    "        image_name = \"user\" + str(id) +'.jpg'\n",
    "        cv2.imwrite(image_name, frame)\n",
    "        print(image_name)\n",
    "    # Display the output\n",
    "    cv2.imshow('Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if id >=5:        \n",
    "        break\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This jupyter notebook is to match face of a given photo with all the faces from photos folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mtcnn = MTCNN(image_size=240, margin=0, min_face_size=20) # initializing mtcnn for face detection\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval() # initializing resnet for face img to embeding conversion\n",
    "\n",
    "dataset=datasets.ImageFolder('photos') # photos folder path \n",
    "idx_to_class = {i:c for c,i in dataset.class_to_idx.items()} # accessing names of peoples from folder names\n",
    "\n",
    "def collate_fn(x):\n",
    "    return x[0]\n",
    "\n",
    "loader = DataLoader(dataset, collate_fn=collate_fn)\n",
    "\n",
    "face_list = [] # list of cropped faces from photos folder\n",
    "name_list = [] # list of names corrospoing to cropped photos\n",
    "embedding_list = [] # list of embeding matrix after conversion from cropped faces to embedding matrix using resnet\n",
    "\n",
    "for img, idx in loader:\n",
    "    face, prob = mtcnn(img, return_prob=True) \n",
    "    if face is not None and prob>0.90: # if face detected and porbability > 90%\n",
    "        emb = resnet(face.unsqueeze(0)) # passing cropped face into resnet model to get embedding matrix\n",
    "        embedding_list.append(emb.detach()) # resulten embedding matrix is stored in a list\n",
    "        name_list.append(idx_to_class[idx]) # names are stored in a list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data into data.pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [embedding_list, name_list]\n",
    "torch.save(data, 'data.pt') # saving data.pt file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching face id of the given photo with available data from data.pt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user1.jpg\n",
      "user2.jpg\n",
      "user3.jpg\n",
      "user4.jpg\n",
      "user5.jpg\n",
      "Image didn't match\n",
      "Face matched with:  angelina_jolie With distance:  1.2905322313308716\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def face_match(img_path, data_path): # img_path= location of photo, data_path= location of data.pt \n",
    "    # getting embedding matrix of the given img\n",
    "    img = Image.open(img_path)\n",
    "    face, prob = mtcnn(img, return_prob=True) # returns cropped face and probability\n",
    "    emb = resnet(face.unsqueeze(0)).detach() # detech is to make required gradient false\n",
    "    \n",
    "    saved_data = torch.load('data.pt') # loading data.pt file\n",
    "    embedding_list = saved_data[0] # getting embedding data\n",
    "    name_list = saved_data[1] # getting list of names\n",
    "    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "    \n",
    "    for idx, emb_db in enumerate(embedding_list):\n",
    "        dist = torch.dist(emb, emb_db).item()\n",
    "        dist_list.append(dist)\n",
    "        \n",
    "    idx_min = dist_list.index(min(dist_list))\n",
    "    return (name_list[idx_min], min(dist_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    exit(0)\n",
    "\n",
    "\n",
    "frameFrequency=25\n",
    "\n",
    "\n",
    "total_frame = 0\n",
    "id = 0\n",
    "while True:\n",
    "\n",
    "        \n",
    "        ret, frame = cap.read(0)\n",
    "        cv2.imshow('image',frame)\n",
    "        if ret is False:\n",
    "            break\n",
    "        total_frame += 1\n",
    "        if total_frame%frameFrequency == 0:\n",
    "            id += 1\n",
    "            image_name = \"user\" + str(id) +'.jpg'\n",
    "            cv2.imwrite(image_name, frame)\n",
    "            print(image_name)\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "            break\n",
    "        if id >=5:\n",
    "            break\n",
    "\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# import cv2\n",
    "\n",
    "# cam = cv2.VideoCapture(0)\n",
    "\n",
    "# cv2.namedWindow(\"test\")\n",
    "\n",
    "# img_counter = 0\n",
    "\n",
    "# while True:\n",
    "    \n",
    "#     ret, frame = cam.read()\n",
    "#     if not ret:\n",
    "#         print(\"failed to grab frame\")\n",
    "#         break\n",
    "#     cv2.imshow(\"test\", frame)\n",
    "\n",
    "#     k = cv2.waitKey(1)\n",
    "#     if k%256 == 27:\n",
    "#         # ESC pressed\n",
    "# #         print(\"Escape hit, closing...\")\n",
    "#         break\n",
    "#     elif k%256 == 32:\n",
    "#         # SPACE pressed\n",
    "#         img_name = \"user{}.png\".format(img_counter)\n",
    "#         cv2.imwrite(img_name, frame)\n",
    "#         print(\" image {} clicked \".format(img_name))\n",
    "#         img_counter += 1\n",
    "#     if img_counter>5:\n",
    "#         break\n",
    "        \n",
    "    \n",
    "\n",
    "# cam.release()\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "z=0\n",
    "total_images_to_be_clicked=5\n",
    "for i in range(1,6):\n",
    "    name = \"user\" +str(i) +\".jpg\"\n",
    "# name=\"user3.jpg\"\n",
    "    result = face_match(name, 'data.pt')\n",
    "    \n",
    "    z = z+ result[1]\n",
    "    \n",
    "z=z/total_images_to_be_clicked\n",
    "if(z>0.5):\n",
    "    print(\"Image didn't match\")\n",
    "elif(z<=0.5):\n",
    "    print(\"Image matched with existing user\")\n",
    "\n",
    "print('Face matched with: ',result[0], 'With distance: ',result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('angelina_jolie', 1.3243240118026733)\n",
      "1.3243240118026733\n",
      "('angelina_jolie', 1.3289611339569092)\n",
      "2.6532851457595825\n",
      "('angelina_jolie', 1.3494564294815063)\n",
      "4.002741575241089\n",
      "('angelina_jolie', 1.3276314735412598)\n",
      "5.330373048782349\n",
      "('angelina_jolie', 1.3513246774673462)\n",
      "6.681697726249695\n",
      "1.336339545249939\n"
     ]
    }
   ],
   "source": [
    "z= 0\n",
    "for i in range(1,6):\n",
    "    name = \"user\" + str(i) +\".jpg\"\n",
    "    result = face_match(name,'data.pt')\n",
    "    print(result)\n",
    "    z= result[1] +z\n",
    "    print(z)\n",
    "    \n",
    "print(z/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[224 171 244 244]]\n",
      "[[224 170 246 246]]\n",
      "[[221 168 252 252]]\n",
      "[[218 164 261 261]]\n",
      "[[218 164 261 261]]\n",
      "[[226 168 250 250]]\n",
      "[[226 168 250 250]]\n",
      "[[226 167 252 252]]\n",
      "[[227 166 254 254]]\n",
      "[[230 166 249 249]]\n",
      "[[230 166 249 249]]\n",
      "[[229 166 250 250]]\n",
      "[[231 166 246 246]]\n",
      "[[231 166 246 246]]\n",
      "[[233 166 244 244]]\n",
      "[[239 169 236 236]]\n",
      "[[240 169 235 235]]\n",
      "[[243 172 230 230]]\n",
      "[[242 171 230 230]]\n",
      "[[243 170 231 231]]\n",
      "[[247 172 224 224]]\n",
      "[[247 173 224 224]]\n",
      "[[247 171 226 226]]\n",
      "[[250 173 219 219]]\n",
      "[[250 173 220 220]]\n",
      "user1.jpg\n",
      "[[250 174 218 218]]\n",
      "[[252 174 217 217]]\n",
      "[[251 174 218 218]]\n",
      "[[251 174 218 218]]\n",
      "[[251 174 218 218]]\n",
      "[[251 175 217 217]]\n",
      "[[251 174 216 216]]\n",
      "[[253 176 213 213]]\n",
      "[[252 175 214 214]]\n",
      "[[255 175 211 211]]\n",
      "[[254 170 216 216]]\n",
      "[[255 169 217 217]]\n",
      "[[255 170 217 217]]\n",
      "[[255 169 221 221]]\n",
      "[[257 169 221 221]]\n",
      "[[261 171 216 216]]\n",
      "[[263 172 213 213]]\n",
      "[[261 171 215 215]]\n",
      "[[258 169 218 218]]\n",
      "[[257 170 217 217]]\n",
      "[[248 169 219 219]]\n",
      "[[248 172 214 214]]\n",
      "[[243 170 219 219]]\n",
      "[[244 171 217 217]]\n",
      "[[243 170 218 218]]\n",
      "user2.jpg\n",
      "[[243 170 218 218]]\n",
      "[[244 170 219 219]]\n",
      "[[246 173 214 214]]\n",
      "[[248 172 214 214]]\n",
      "[[246 172 215 215]]\n",
      "[[246 172 216 216]]\n",
      "[[244 169 221 221]]\n",
      "[[246 171 215 215]]\n",
      "[[245 169 218 218]]\n",
      "[[246 171 217 217]]\n",
      "[[248 170 216 216]]\n",
      "[[247 170 217 217]]\n",
      "[[247 170 217 217]]\n",
      "[[248 170 216 216]]\n",
      "[[248 170 216 216]]\n",
      "[[248 170 216 216]]\n",
      "[[248 170 217 217]]\n",
      "[[249 171 213 213]]\n",
      "[[249 171 214 214]]\n",
      "[[249 170 213 213]]\n",
      "[[248 169 215 215]]\n",
      "[[248 171 212 212]]\n",
      "[[247 171 213 213]]\n",
      "[[248 170 214 214]]\n",
      "[[247 171 214 214]]\n",
      "user3.jpg\n",
      "[[248 171 214 214]]\n",
      "[[248 170 215 215]]\n",
      "[[247 168 217 217]]\n",
      "[[247 169 217 217]]\n",
      "[[247 169 216 216]]\n",
      "[[249 172 212 212]]\n",
      "[[249 171 214 214]]\n",
      "[[247 170 216 216]]\n",
      "[[248 170 217 217]]\n",
      "[[248 172 217 217]]\n",
      "[[251 174 215 215]]\n",
      "[[250 173 216 216]]\n",
      "[[249 174 216 216]]\n",
      "[[247 172 218 218]]\n",
      "[[248 173 218 218]]\n",
      "[[248 173 217 217]]\n",
      "[[249 173 215 215]]\n",
      "[[248 173 217 217]]\n",
      "[[248 172 218 218]]\n",
      "[[248 172 218 218]]\n",
      "[[250 173 213 213]]\n",
      "[[249 173 215 215]]\n",
      "[[250 172 215 215]]\n",
      "[[248 172 218 218]]\n",
      "[[248 172 218 218]]\n",
      "user4.jpg\n",
      "[[248 172 216 216]]\n",
      "[[248 172 217 217]]\n",
      "[[249 172 216 216]]\n",
      "[[251 173 214 214]]\n",
      "[[249 172 216 216]]\n",
      "[[247 171 219 219]]\n",
      "[[249 173 216 216]]\n",
      "[[250 174 214 214]]\n",
      "[[250 172 217 217]]\n",
      "[[256 175 211 211]]\n",
      "[[265 175 211 211]]\n",
      "[[266 172 218 218]]\n",
      "[[269 175 216 216]]\n",
      "[[273 174 219 219]]\n",
      "[[273 173 222 222]]\n",
      "[[271 172 225 225]]\n",
      "[[270 172 227 227]]\n",
      "[[272 175 217 217]]\n",
      "[[271 178 208 208]]\n",
      "[[263 176 212 212]]\n",
      "[[252 174 214 214]]\n",
      "[[242 172 213 213]]\n",
      "[[240 174 210 210]]\n",
      "[[236 172 212 212]]\n",
      "[[231 173 206 206]]\n",
      "user5.jpg\n",
      "Image matched with existing user\n",
      "Face matched with:  kashif With distance:  0.6709874987602233\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def draw_rect(img, faces, sf=20):\n",
    "    for x, y, w, h in faces:\n",
    "        x = x - sf\n",
    "        y = y - 2*sf\n",
    "        cv2.rectangle(img, (x,y), (x+w+2*sf, y+h+3*sf), (255, 0 , 0), 3)\n",
    "\n",
    "        \n",
    "        \n",
    "       \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "frameFrequency=25\n",
    "total_frame = 0\n",
    "id = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read(0)\n",
    "\n",
    "    if ret is False:\n",
    "        break\n",
    "\n",
    "    faces = face_detector.detectMultiScale(frame, 1.1, 4)\n",
    "    print(faces)\n",
    "\n",
    "    draw_rect(frame, faces)\n",
    "    \n",
    "    total_frame += 1\n",
    "    if total_frame%frameFrequency == 0:\n",
    "        id += 1\n",
    "        image_name = \"user\" + str(id) +'.jpg'\n",
    "        cv2.imwrite(image_name, frame)\n",
    "        print(image_name)\n",
    "    # Display the output\n",
    "    cv2.imshow('Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    if id >=5:        \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "def face_match(img_path, data_path): # img_path= location of photo, data_path= location of data.pt \n",
    "    # getting embedding matrix of the given img\n",
    "    img = Image.open(img_path)\n",
    "    face, prob = mtcnn(img, return_prob=True) # returns cropped face and probability\n",
    "    emb = resnet(face.unsqueeze(0)).detach() # detech is to make required gradient false\n",
    "    \n",
    "    saved_data = torch.load('data.pt') # loading data.pt file\n",
    "    embedding_list = saved_data[0] # getting embedding data\n",
    "    name_list = saved_data[1] # getting list of names\n",
    "    dist_list = [] # list of matched distances, minimum distance is used to identify the person\n",
    "    \n",
    "    for idx, emb_db in enumerate(embedding_list):\n",
    "        dist = torch.dist(emb, emb_db).item()\n",
    "        dist_list.append(dist)\n",
    "        \n",
    "    idx_min = dist_list.index(min(dist_list))\n",
    "    return (name_list[idx_min], min(dist_list))\n",
    "\n",
    "\n",
    "\n",
    "z=0\n",
    "total_images_to_be_clicked=5\n",
    "for i in range(1,6):\n",
    "    name = \"user\" +str(i) +\".jpg\"\n",
    "# name=\"user3.jpg\"\n",
    "    result = face_match(name, 'data.pt')\n",
    "    \n",
    "    z = z+ result[1]\n",
    "    \n",
    "z=z/total_images_to_be_clicked\n",
    "if(z>0.8):\n",
    "    print(\"Image didn't match\")\n",
    "elif(z<=0.8):\n",
    "    print(\"Image matched with existing user\")\n",
    "\n",
    "print('Face matched with: ',result[0], 'With distance: ',z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kashif'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
